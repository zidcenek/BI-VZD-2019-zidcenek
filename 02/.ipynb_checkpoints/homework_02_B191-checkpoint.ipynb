{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Úkol č. 2 - předzpracování dat a binární klasifikace (do 10. listopadu)\n",
    "\n",
    "  * Cílem thoto úkolu je vyzkoušet si naučit prediktivní model pro binární klasifikaci.\n",
    "  * Budete se muset vypořádat s příznaky, které jsou různých typů a které bude třeba nějakým způsobem převést do číselné reprezentace.\n",
    "    \n",
    "> **Úkoly jsou zadány tak, aby Vám daly prostor pro invenci. Vymyslet _jak přesně_ budete úkol řešit, je důležitou součástí zadání a originalita či nápaditost bude také hodnocena!**\n",
    "\n",
    "## Zdroj dat\n",
    "\n",
    "Budeme se zabývat predikcí přežití pasažérů Titaniku.\n",
    "K dispozici máte trénovací data v souboru **data.csv** a data na vyhodnocení v souboru **evaluation.csv**.\n",
    "\n",
    "#### Seznam příznaků:\n",
    "* survived - zda přežil, 0 = Ne, 1 = Ano, **vysvětlovaná proměnná**, kterou chcete predikovat\n",
    "* pclass - Třída lodního lístku, 1 = první, 2 = druhá, 3 = třetí\n",
    "* name - jméno\n",
    "* sex - pohlaví\n",
    "* age - věk v letech\n",
    "* sibsp\t- počet sourozenců / manželů, manželek na palubě\n",
    "* parch - počet rodičů / dětí na palubě\n",
    "* ticket - číslo lodního lístku\n",
    "* fare - cena lodního lístku\n",
    "* cabin\t- číslo kajuty\n",
    "* embarked\t- místo nalodění, C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "* home.dest - Bydliště/Cíl\n",
    "\n",
    "## Pokyny k vypracování\n",
    "\n",
    "**Základní body zadání**, za jejichž (poctivé) vypracování získáte **8 bodů**:\n",
    "  * V Jupyter notebooku načtěte data ze souboru **data.csv**. Vhodným způsobem si je rozdělte na trénovací, testovací a případně i validační množinu (preferujeme ale použití cross-validation).\n",
    "  * Projděte si jednotlivé příznaky a transformujte je do vhodné podoby pro použití ve vybraném klasifikačním modelu.\n",
    "  * Podle potřeby si můžete vytvářet nové příznaky (na základě existujících), například tedy můžete vytvořit příznak měřící délku jména. Některé příznaky můžete také úplně zahodit.\n",
    "  * Nějakým způsobem se vypořádejte s chybějícími hodnotami.\n",
    "  * Následně si vyberte vhodný klasifikační model z přednášek. Najděte vhodné hyperparametry a určete jeho přesnost (accuracy) na trénovací množině. Také určete jeho přesnost na testovací/vaidační množině.\n",
    "  * Načtěte vyhodnocovací data ze souboru **evaluation.csv**. Napočítejte predikce pro tyto data (vysvětlovaná proměnná v nich již není). Vytvořte **results.csv** soubor, ve kterém tyto predikce uložíte do dvou sloupců: ID, predikce přežití. Tento soubor nahrajte do repozitáře.\n",
    "\n",
    "**Další body zadání** za případné další body  (můžete si vybrat, maximum bodů za úkol je každopádně 12 bodů):\n",
    "  * (až +4 body) Aplikujte všechny klasifikační modely z přednášek a určete (na základě přesnosti na validační množině), který je nejlepší. Přesnost tohoto nejlepšího modelu odhadněte pomocí testovací množiny. K predikcím na vyhodnocovacích datech využijte tento model.\n",
    "  * (až +4 body) Zkuste použít nějaké (alespoň dvě) netriviální metody doplňování chybějících hodnot u věku. Zaměřte na vliv těchto metod na přesnost predikce výsledného modelu. K predikcím na vyhodnocovacích datech využijte ten přístup, který Vám vyjde jako nejlepší.\n",
    "\n",
    "## Poznámky k odevzdání\n",
    "\n",
    "  * Řiďte se pokyny ze stránky https://courses.fit.cvut.cz/BI-VZD/homeworks/index.html.\n",
    "  * Odevzdejte nejen Jupyter Notebook, ale i _csv_ soubor(y) s predikcemi pro vyhodnocovací data.\n",
    "  * Opravující Vám může umožnit úkol dodělat či opravit a získat tak další body. **První verze je ale důležitá a bude-li odbytá, budete za to penalizováni**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_data_adjusments(data):\n",
    "    df = data.drop(columns=[\"name\"])\n",
    "    df[\"sex\"].replace(['male','female'],[True,False],inplace=True)\n",
    "    # první písmena kabiny převede na čísla, kde žádná hodnota je 0 a poté postupně G - A se převede na 1 - 7\n",
    "    cabin_level = {\n",
    "        \"1\": \"G\",\n",
    "        \"2\": \"F\",\n",
    "        \"3\": \"E\",\n",
    "        \"4\": \"D\",\n",
    "        \"5\": \"C\",\n",
    "        \"6\": \"B\", \n",
    "        \"7\": \"A\"\n",
    "    }\n",
    "    df['cabin'] = np.where(df['cabin'].isnull(), '0', df['cabin'])\n",
    "    for index, value  in cabin_level.items():\n",
    "       df['cabin'] = np.where(df['cabin'].str.contains(value), index, df['cabin'])\n",
    "    df[\"cabin\"] = df[\"cabin\"].replace(['^[H-Z]'], [1], regex = True)\n",
    "    df['cabin'] = pd.to_numeric(df['cabin'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# řádky s nekompletní hodnotou ve sloupcích fare a embarked vyhodím, protože 3 z 1000 je poměrně málo\n",
    "def drop_incomplete_rows(data):\n",
    "    df = data.loc[data.fare.notnull()]\n",
    "    df = df.loc[data.embarked.notnull()]\n",
    "    home_dest_unique = df.loc[data[\"home.dest\"].notnull()].nunique()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# změna 'home.dest' na sloupce fromUSA a notFromUSA, odhad podle regext '.*, ..$' napr 'Ireland New York, NY'\n",
    "def home_dest_solution(data):\n",
    "    df = data.replace(to_replace ='.*, ..$', value = 'USA', regex = True) \n",
    "    home_dest_column = df[\"home.dest\"]\n",
    "    home_dest_column = home_dest_column.replace(['.+[^U][^S][^A]$', '.*'], [1, 0], regex = True)\n",
    "    home_dest_column = home_dest_column.replace(np.nan, 0)\n",
    "    home_dest_column\n",
    "    df[\"notFromUSA\"] = home_dest_column\n",
    "    df[\"home.dest\"] = df[\"home.dest\"].replace(['USA$', '.*'], [1, 0], regex = True)\n",
    "    df[\"home.dest\"] = df[\"home.dest\"].replace(np.nan, 0)\n",
    "    df.rename(columns = {'home.dest': 'fromUSA'}, inplace=True)\n",
    "    df['notFromUSA'] = pd.to_numeric(df['notFromUSA'], downcast='integer')\n",
    "    df['fromUSA'] = pd.to_numeric(df['fromUSA'], downcast='integer')\n",
    "    df[\"age\"] = df[\"age\"].replace(np.nan, df['age'].median())\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def embarked_solution(data):\n",
    "    df = data.drop(columns = 'ticket')\n",
    "    df.rename(columns = {'embarked': 'embarked S'}, inplace=True)\n",
    "    df['embarked C'] = df['embarked S'].replace(['C', '.'], [1, 0], regex = True)\n",
    "    df['embarked Q'] = df['embarked S'].replace(['Q', '.'], [1, 0], regex = True)\n",
    "    df['embarked S'] = df['embarked S'].replace(['S', '.'], [1, 0], regex = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data_CV(Xdata, ydata, ratio=0.25, rd_seed=5656):\n",
    "    '''\n",
    "        rozdělí pouze na trenovací a testovací, slouží k použití cross validace\n",
    "    '''\n",
    "    Xtrain, Xtest, ytrain, ytest = train_test_split(Xdata, ydata, test_size=0.25, random_state=rd_seed) \n",
    "    return Xtrain, Xtest, ytrain, ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_adjusment(data):\n",
    "    '''\n",
    "        upravení dat\n",
    "    '''\n",
    "    data = basic_data_adjusments(data)\n",
    "    data = drop_incomplete_rows(data)\n",
    "    data = home_dest_solution(data)\n",
    "    data = embarked_solution(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv')\n",
    "data = data_adjusment(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_forest(Xtrain, ytrain, number_of_cv):\n",
    "    param_grid_forest = {\n",
    "        'n_estimators': range(4,40,2),\n",
    "        'max_depth': range(3,8),\n",
    "        'criterion': ['gini', 'entropy']\n",
    "    }\n",
    "    param_comb = ParameterGrid(param_grid_forest)\n",
    "    val_acc_forest = []\n",
    "    for params in param_comb:\n",
    "        params['random_state'] = random_state\n",
    "        dt = RandomForestClassifier(**params)\n",
    "        scores = cross_validate(dt, Xtrain, ytrain, cv=number_of_cv)\n",
    "        val_acc_forest.append(np.average(scores['test_score']))\n",
    "    best_params = param_comb[np.argmax(val_acc_forest)]\n",
    "    print(best_params)\n",
    "    print(\"Nejlepší přesnost po cross validaci lesu\", max(val_acc_forest))\n",
    "    return {'best_params': best_params, 'val_acc': max(val_acc_forest), 'type': 'forest'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def learn_tree(Xtrain, ytrain, number_of_cv):\n",
    "    param_grid_tree = {\n",
    "        'max_depth': range(2,20), \n",
    "        'criterion': ['entropy', 'gini'],\n",
    "        'splitter': ['best', 'random']\n",
    "    }\n",
    "    param_comb = ParameterGrid(param_grid_tree)    \n",
    "    val_acc_tree = []\n",
    "\n",
    "    for params in param_comb:\n",
    "        params['random_state'] = random_state\n",
    "        dt = DecisionTreeClassifier(**params)\n",
    "        scores = cross_validate(dt, Xtrain, ytrain, cv=number_of_cv)\n",
    "        val_acc_tree.append(np.average(scores['test_score']))  \n",
    "\n",
    "    best_params = param_comb[np.argmax(val_acc_tree)]\n",
    "    print(best_params)\n",
    "    print(\"Nejlepší přesnost po cross validaci stromu\", max(val_acc_tree))\n",
    "    return {'best_params': best_params, 'val_acc': max(val_acc_tree), 'type': 'tree'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_ada(Xtrain, ytrain, number_of_cv):\n",
    "    param_grid_ada = {\n",
    "        'n_estimators': range(10,50,1),\n",
    "        'learning_rate': [0.8, 1.2, 1.5, 1.7]\n",
    "    }\n",
    "    param_comb = ParameterGrid(param_grid_ada)    \n",
    "    val_acc_ada = []\n",
    "\n",
    "    for params in param_comb:\n",
    "        params['random_state'] = random_state\n",
    "        dt = AdaBoostClassifier(**params)\n",
    "        scores = cross_validate(dt, Xtrain, ytrain, cv=number_of_cv)\n",
    "        val_acc_ada.append(np.average(scores['test_score']))\n",
    "\n",
    "    best_params = param_comb[np.argmax(val_acc_ada)]\n",
    "    print(best_params)\n",
    "    print(\"Nejlepší přesnost po cross validaci ada-boostu\", max(val_acc_ada))\n",
    "    return {'best_params': best_params, 'val_acc': max(val_acc_ada), 'type': 'ada'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_knn(Xtrain, ytrain, number_of_cv):\n",
    "    param_grid_knn = {\n",
    "        'n_neighbors': range(4,20,1),\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'leaf_size': range(10, 71, 10),\n",
    "        'p': range(1, 3)\n",
    "    }\n",
    "    param_comb = ParameterGrid(param_grid_knn)    \n",
    "    val_acc_knn = []\n",
    "    for params in param_comb:\n",
    "        dt = KNeighborsClassifier(**params)\n",
    "        scores = cross_validate(dt, Xtrain, ytrain, cv=number_of_cv)\n",
    "        val_acc_knn.append(np.average(scores['test_score']))  \n",
    "\n",
    "    best_params = param_comb[np.argmax(val_acc_knn)]\n",
    "    print(best_params)\n",
    "    print(\"Nejlepší přesnost po cross validaci kNN\", max(val_acc_knn))\n",
    "    return {'best_params': best_params, 'val_acc': max(val_acc_knn), 'type': 'knn'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(Xtrain, ytrain, number_of_cv = 4):\n",
    "    results = []\n",
    "    results.append(learn_forest(Xtrain, ytrain, number_of_cv))\n",
    "    results.append(learn_tree(Xtrain, ytrain, number_of_cv))\n",
    "    results.append(learn_ada(Xtrain, ytrain, number_of_cv))\n",
    "    results.append(learn_knn(Xtrain, ytrain, number_of_cv))\n",
    "    scores = []\n",
    "    for item in results:\n",
    "        scores.append(item['val_acc'])\n",
    "    return results[np.argmax(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 32, 'max_depth': 5, 'criterion': 'gini'}\n",
      "Nejlepší přesnost po cross validaci lesu 0.8246055380239122\n",
      "{'splitter': 'random', 'max_depth': 3, 'criterion': 'gini'}\n",
      "Nejlepší přesnost po cross validaci stromu 0.8206320280901374\n",
      "{'n_estimators': 27, 'learning_rate': 1.5}\n",
      "Nejlepší přesnost po cross validaci ada-boostu 0.8098582159207076\n",
      "{'weights': 'distance', 'p': 1, 'n_neighbors': 13, 'leaf_size': 10}\n",
      "Nejlepší přesnost po cross validaci kNN 0.6505355793590826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'best_params': {'n_estimators': 32, 'max_depth': 5, 'criterion': 'gini'},\n",
       " 'val_acc': 0.8246055380239122,\n",
       " 'type': 'forest'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = split_data_CV(data.drop(columns=['survived']), data.survived)\n",
    "random_state = 365412\n",
    "number_of_cv = 5\n",
    "# learn_forest(Xtrain, ytrain, number_of_cv)\n",
    "best_result = cross_validation(Xtrain, ytrain, number_of_cv)\n",
    "best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Přesnost na testovací množině dat je 0.792\n"
     ]
    }
   ],
   "source": [
    "best_params = best_result['best_params']\n",
    "dt = None\n",
    "if best_result['type'] == 'forest':\n",
    "    best_params['random_state'] = random_state\n",
    "    dt = RandomForestClassifier(**best_params)\n",
    "elif best_result['type'] == 'tree':\n",
    "    best_params['random_state'] = random_state\n",
    "    dt = DecisionTreeClassifier(**best_params)\n",
    "elif best_result['type'] == 'ada':\n",
    "    best_params['random_state'] = random_state\n",
    "    dt = AdaBoostClassifier(**best_params)\n",
    "else:\n",
    "    dt = KNeighborsClassifier(**best_params)\n",
    "    \n",
    "dt.fit(Xtrain, ytrain)\n",
    "print(\"Přesnost na testovací množině dat je\", metrics.accuracy_score(ytest, dt.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"evaluation.csv\")\n",
    "test_data = data_adjusment(test_data)\n",
    "a = dt.predict(test_data)\n",
    "df = pd.DataFrame()\n",
    "df[\"ID\"] = test_data[\"ID\"]\n",
    "df[\"prediction\"] = a\n",
    "df.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1002</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1004</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1006</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1007</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1009</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1011</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1013</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1014</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1016</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1017</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1018</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1019</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1021</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1024</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1025</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1026</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1027</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1029</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>1279</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>1280</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>1281</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>1282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>1283</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1284</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>1285</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>1286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>1287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>1288</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>1289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>1290</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>1291</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>1292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>1293</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>1294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>1295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>1296</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>1297</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>1298</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>1299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>1301</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>1302</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>1303</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1304</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>1305</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>1307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ID  prediction\n",
       "0    1000           0\n",
       "1    1001           0\n",
       "2    1002           0\n",
       "3    1003           0\n",
       "4    1004           0\n",
       "5    1005           0\n",
       "6    1006           1\n",
       "7    1007           0\n",
       "8    1008           0\n",
       "9    1009           0\n",
       "10   1010           0\n",
       "11   1011           0\n",
       "12   1012           1\n",
       "13   1013           1\n",
       "14   1014           0\n",
       "15   1015           0\n",
       "16   1016           0\n",
       "17   1017           0\n",
       "18   1018           0\n",
       "19   1019           0\n",
       "20   1020           0\n",
       "21   1021           0\n",
       "22   1022           1\n",
       "23   1023           1\n",
       "24   1024           0\n",
       "25   1025           0\n",
       "26   1026           0\n",
       "27   1027           0\n",
       "28   1028           1\n",
       "29   1029           1\n",
       "..    ...         ...\n",
       "279  1279           0\n",
       "280  1280           0\n",
       "281  1281           0\n",
       "282  1282           0\n",
       "283  1283           0\n",
       "284  1284           0\n",
       "285  1285           0\n",
       "286  1286           1\n",
       "287  1287           0\n",
       "288  1288           1\n",
       "289  1289           0\n",
       "290  1290           0\n",
       "291  1291           0\n",
       "292  1292           1\n",
       "293  1293           0\n",
       "294  1294           1\n",
       "295  1295           0\n",
       "296  1296           0\n",
       "297  1297           0\n",
       "298  1298           0\n",
       "299  1299           0\n",
       "300  1300           0\n",
       "301  1301           0\n",
       "302  1302           0\n",
       "303  1303           0\n",
       "304  1304           0\n",
       "305  1305           0\n",
       "306  1306           0\n",
       "307  1307           0\n",
       "308  1308           0\n",
       "\n",
       "[309 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv(\"result.csv\")\n",
    "df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
